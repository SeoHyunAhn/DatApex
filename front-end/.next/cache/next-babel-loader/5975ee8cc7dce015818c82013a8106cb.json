{"ast":null,"code":"import _classCallCheck from \"@babel/runtime-corejs2/helpers/esm/classCallCheck\";\nimport _createClass from \"@babel/runtime-corejs2/helpers/esm/createClass\";\nimport _possibleConstructorReturn from \"@babel/runtime-corejs2/helpers/esm/possibleConstructorReturn\";\nimport _getPrototypeOf from \"@babel/runtime-corejs2/helpers/esm/getPrototypeOf\";\nimport _inherits from \"@babel/runtime-corejs2/helpers/esm/inherits\";\nvar _jsxFileName = \"/Users/harsha.valluri/Desktop/cs407/DatApex/front-end/pages/mlOptions.js\";\nvar __jsx = React.createElement;\nimport React, { Component } from \"react\";\nimport Layout from \"../components/layout\"; // import Link from 'next/link';\n\nimport { Link, Router } from \"../routes\";\nvar styleCard = {\n  marginBottom: \"10px\"\n};\n\nvar MlOptions =\n/*#__PURE__*/\nfunction (_Component) {\n  _inherits(MlOptions, _Component);\n\n  function MlOptions() {\n    _classCallCheck(this, MlOptions);\n\n    return _possibleConstructorReturn(this, _getPrototypeOf(MlOptions).apply(this, arguments));\n  }\n\n  _createClass(MlOptions, [{\n    key: \"render\",\n    value: function render() {\n      return __jsx(React.Fragment, null, __jsx(\"h1\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 14\n        },\n        __self: this\n      }, \"Machine Learning Algorithms\"), __jsx(\"hr\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 15\n        },\n        __self: this\n      }), __jsx(\"div\", {\n        className: \"container-fluid\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 16\n        },\n        __self: this\n      }, __jsx(\"div\", {\n        className: \"row\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 17\n        },\n        __self: this\n      }, __jsx(\"div\", {\n        className: \"col-6\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 18\n        },\n        __self: this\n      }, __jsx(\"div\", {\n        className: \"card\",\n        style: {\n          styleCard: styleCard\n        },\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 19\n        },\n        __self: this\n      }, __jsx(\"div\", {\n        className: \"card-header\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 20\n        },\n        __self: this\n      }, \"Naive Bayes Algorithm\"), __jsx(\"div\", {\n        className: \"card-body\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 21\n        },\n        __self: this\n      }, __jsx(\"img\", {\n        className: \"card-img\",\n        variant: \"top\",\n        src: \"../static/nba.png\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 22\n        },\n        __self: this\n      }), __jsx(\"h5\", {\n        className: \"card-title\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 27\n        },\n        __self: this\n      }, \"Explanation: \"), __jsx(\"p\", {\n        className: \"card-text\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 28\n        },\n        __self: this\n      }, \"Na\\xEFve Bayes is a classification technique/algorithm based on Bayes\\u2019 Theorem with an assumption of independence among the predictors. Loosely translated, this means that a Na\\xEFve Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature. This model is particularly useful for large data sets \\u2013 along with simplicity, Na\\xEFve Bayes is known to outperform even highly sophisticated classification methods in some cases. \", __jsx(\"br\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 37\n        },\n        __self: this\n      }), \"The Na\\xEFve Bayes algorithm works by converting the dataset into a frequency table, creating a likelihood table by calculating probabilities & then using the Na\\xEFve Bayes equation to calculate the posterior probability for each class. The class with the highest posterior probability is considered the outcome of the prediction. This algorithm is typically used in text classification & with problems having multiple classes.\"), __jsx(Link, {\n        route: \"mlalgo\",\n        params: {\n          path: \"nba\"\n        },\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 46\n        },\n        __self: this\n      }, __jsx(\"a\", {\n        className: \"btn btn-primary\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 47\n        },\n        __self: this\n      }, \"Try Now\"))))), __jsx(\"div\", {\n        className: \"col-6\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 52\n        },\n        __self: this\n      }, __jsx(\"div\", {\n        className: \"card\",\n        style: {\n          styleCard: styleCard\n        },\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 53\n        },\n        __self: this\n      }, __jsx(\"div\", {\n        className: \"card-header\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 54\n        },\n        __self: this\n      }, \"Logistic Regression Algorithm\"), __jsx(\"div\", {\n        className: \"card-body\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 55\n        },\n        __self: this\n      }, __jsx(\"img\", {\n        className: \"card-img\",\n        variant: \"top\",\n        src: \"../static/lra.png\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 56\n        },\n        __self: this\n      }), __jsx(\"h5\", {\n        className: \"card-title\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 61\n        },\n        __self: this\n      }, \"Explanation: \"), __jsx(\"p\", {\n        className: \"card-text\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 62\n        },\n        __self: this\n      }, \"Logistic Regression is a classification machine-learning algorithm used to assign observations to a discrete set of classes (binary or multiple classes). Logistic regression transforms its output using the logistic sigmoid function to return a probability value. Logistic Regression is a predictive analysis algorithm as it is based on the concepts of probability. It uses a more complex cost function than linear regression (the logistic or sigmoid function).\", __jsx(\"br\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 71\n        },\n        __self: this\n      }), \"In order to map predicted values to probabilities, we use the Sigmoid function which maps any real value into another value between 0 & 1.\"), __jsx(Link, {\n        route: \"mlalgo\",\n        params: {\n          path: \"lra\"\n        },\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 76\n        },\n        __self: this\n      }, __jsx(\"a\", {\n        className: \"btn btn-primary\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 77\n        },\n        __self: this\n      }, \"Try Now\")))))), __jsx(\"hr\", {\n        className: \"w-100\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 83\n        },\n        __self: this\n      }), __jsx(\"div\", {\n        className: \"row\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 84\n        },\n        __self: this\n      }, __jsx(\"div\", {\n        className: \"col-6\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 85\n        },\n        __self: this\n      }, __jsx(\"div\", {\n        className: \"card\",\n        style: {\n          styleCard: styleCard\n        },\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 86\n        },\n        __self: this\n      }, __jsx(\"div\", {\n        className: \"card-header\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 87\n        },\n        __self: this\n      }, \"Support Vector Machine Algorithm\"), __jsx(\"div\", {\n        className: \"card-body\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 90\n        },\n        __self: this\n      }, __jsx(\"img\", {\n        className: \"card-img\",\n        variant: \"top\",\n        src: \"../static/svm.png\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 91\n        },\n        __self: this\n      }), __jsx(\"h5\", {\n        className: \"card-title\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 96\n        },\n        __self: this\n      }, \"Explanation: \"), __jsx(\"p\", {\n        className: \"card-text\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 97\n        },\n        __self: this\n      }, \"SVM is a supervised machine learning algorithm which may be used for either classification or regression problems. However, in general, it is used predominantly for classification problems. In this algorithm, we plot each data item as a point in n-dimensional space (n being the number of features) with the value of each feature being the value of a particular coordinate. Subsequently, classification is performed by finding the hyperplane (the equivalent of a line in a 2-dimensional space) that differentiates the two classes well. \", __jsx(\"br\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 107\n        },\n        __self: this\n      }), \"Above image shows, Support Vectors are simply the co-ordinates of individual observations. SVM is a frontier which best segregates the two classes.\"), __jsx(Link, {\n        route: \"mlalgo\",\n        params: {\n          path: \"svm\"\n        },\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 112\n        },\n        __self: this\n      }, __jsx(\"a\", {\n        className: \"btn btn-primary\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 113\n        },\n        __self: this\n      }, \"Try Now\"))))), __jsx(\"div\", {\n        className: \"col-6\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 118\n        },\n        __self: this\n      }, __jsx(\"div\", {\n        className: \"card\",\n        style: {\n          styleCard: styleCard\n        },\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 119\n        },\n        __self: this\n      }, __jsx(\"div\", {\n        className: \"card-header\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 120\n        },\n        __self: this\n      }, \"Bagging Algorithm\"), __jsx(\"div\", {\n        className: \"card-body\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 121\n        },\n        __self: this\n      }, __jsx(\"img\", {\n        className: \"card-img\",\n        variant: \"top\",\n        src: \"../static/bag.png\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 122\n        },\n        __self: this\n      }), __jsx(\"h5\", {\n        className: \"card-title\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 127\n        },\n        __self: this\n      }, \"Explanation: \"), __jsx(\"p\", {\n        className: \"card-text\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 128\n        },\n        __self: this\n      }, \"Bagging algorithm is a simple yet powerful ensemble method. An ensemble method is one that combines predictions from multiple machine learning algorithms together to make more accurate predictions than any individual method.\", \"This method is especially helpful in reducing the variance for algorithms which tend to have really high variance. Bagging involves applying the Bootstrapping procedure to a high-variance machine learning algorithm (typically decision trees).\", __jsx(\"br\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 139\n        },\n        __self: this\n      }), __jsx(\"br\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 140\n        },\n        __self: this\n      }), \"Let\\u2019s assume we have a sample dataset of 1000 instances & we are using the CART algorithm. Bagging would work as follows:\", __jsx(\"br\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 143\n        },\n        __self: this\n      }), \"- Create several (e.g. 100) random sub-samples of the dataset with replacement.\", __jsx(\"br\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 145\n        },\n        __self: this\n      }), \"- Train a CART model on each sample.\", __jsx(\"br\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 146\n        },\n        __self: this\n      }), \"- Given a new dataset, calculate the average prediction from each model.\", __jsx(\"br\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 148\n        },\n        __self: this\n      }), __jsx(\"br\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 149\n        },\n        __self: this\n      }), \"Bagging may be used for either classification or regression problems.\"), __jsx(Link, {\n        route: \"mlalgo\",\n        params: {\n          path: \"bag\"\n        },\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 153\n        },\n        __self: this\n      }, __jsx(\"a\", {\n        className: \"btn btn-primary\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 154\n        },\n        __self: this\n      }, \"Try Now\")))))), __jsx(\"hr\", {\n        className: \"w-100\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 160\n        },\n        __self: this\n      }), __jsx(\"div\", {\n        className: \"row\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 161\n        },\n        __self: this\n      }, __jsx(\"div\", {\n        className: \"col-6\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 162\n        },\n        __self: this\n      }, __jsx(\"div\", {\n        className: \"card\",\n        style: {\n          styleCard: styleCard\n        },\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 163\n        },\n        __self: this\n      }, __jsx(\"div\", {\n        className: \"card-header\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 164\n        },\n        __self: this\n      }, \"K-means Clustering Algorithm\"), __jsx(\"div\", {\n        className: \"card-body\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 165\n        },\n        __self: this\n      }, __jsx(\"img\", {\n        className: \"card-img\",\n        variant: \"top\",\n        src: \"../static/clus.png\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 166\n        },\n        __self: this\n      }), __jsx(\"h5\", {\n        className: \"card-title\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 171\n        },\n        __self: this\n      }, \"Explanation: \"), __jsx(\"p\", {\n        className: \"card-text\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 172\n        },\n        __self: this\n      }, \"K-means Clustering is one of the simplest and most popular unsupervised machine learning algorithms. Typically, unsupervised machine learning algorithms make inferences from datasets using only input vectors without referring to known/labelled outcomes.\", __jsx(\"br\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 178\n        },\n        __self: this\n      }), \"A cluster, simply put, refers to a collection of data points aggregated together because of certain similarities. The \\u2018k\\u2019 from the name refers to the number of centroids needed in the dataset, and is defined by us. A centroid is the imaginary or real location representing the center of the cluster. The \\u2018means\\u2019 in the K-Means refers to the averaging of data (i.e. finding the centroid).\", __jsx(\"br\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 186\n        },\n        __self: this\n      }), __jsx(\"br\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 187\n        },\n        __self: this\n      }), \"The algorithm starts with a first group of randomly selected centroids that are used as beginning points for every cluster, and then performs iterative calculations to optimize the positions of the centroids. It stops creating or optimizing clusters when:\", __jsx(\"br\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 193\n        },\n        __self: this\n      }), \"- The centroids have stabilized, i.e. there is no change in their values because the clustering has been successful;\", __jsx(\"br\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 196\n        },\n        __self: this\n      }), \"- The defined number of iterations has been reached.\"), __jsx(Link, {\n        route: \"mlalgo\",\n        params: {\n          path: \"clus\"\n        },\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 198\n        },\n        __self: this\n      }, __jsx(\"a\", {\n        className: \"btn btn-primary\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 199\n        },\n        __self: this\n      }, \"Try Now\"))))), __jsx(\"div\", {\n        className: \"col-6\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 204\n        },\n        __self: this\n      }, __jsx(\"div\", {\n        className: \"card\",\n        style: {\n          styleCard: styleCard\n        },\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 205\n        },\n        __self: this\n      }, __jsx(\"div\", {\n        className: \"card-header\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 206\n        },\n        __self: this\n      }, \"Decision Tree Algorithm\"), __jsx(\"div\", {\n        className: \"card-body\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 207\n        },\n        __self: this\n      }, __jsx(\"img\", {\n        className: \"card-img\",\n        variant: \"top\",\n        src: \"../static/tree.png\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 208\n        },\n        __self: this\n      }), __jsx(\"h5\", {\n        className: \"card-title\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 213\n        },\n        __self: this\n      }, \"Explanation: \"), __jsx(\"p\", {\n        className: \"card-text\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 214\n        },\n        __self: this\n      }, \"Decision Tree algorithm belongs to the family of supervised machine learning algorithms. Unlike other supervised learning algorithms, this algorithm can be used for solving regression & classification problems too. The general model of Decision Trees algorithm is to create a training model which can be used to predict the class or value of target variables by learning decision rules inferred from the training data.\", __jsx(\"br\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 223\n        },\n        __self: this\n      }), __jsx(\"br\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 224\n        },\n        __self: this\n      }), \"As the name insinuates, this algorithm uses a tree representation to solve the problem, wherein each internal node corresponds to an attribute while each leaf node corresponds to a class label. A rough outline of the algorithm is as follows:\", __jsx(\"br\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 230\n        },\n        __self: this\n      }), \"- Place the best attribute of the dataset at the root of the tree.\", __jsx(\"br\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 232\n        },\n        __self: this\n      }), \"- Split the training set into subsets in such a way that each subset contains data with the same value for an attribute.\", __jsx(\"br\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 235\n        },\n        __self: this\n      }), \"- Repeat the previous two steps on each subset until leaf nodes are found in all branches of the tree.\", __jsx(\"br\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 237\n        },\n        __self: this\n      }), __jsx(\"br\", {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 238\n        },\n        __self: this\n      }), \"With decision trees, one of the biggest challenges is to identify which attributes need to be considered as the root node and each level.\"), __jsx(Link, {\n        route: \"mlalgo\",\n        params: {\n          path: \"tree\"\n        },\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 243\n        },\n        __self: this\n      }, __jsx(\"a\", {\n        className: \"btn btn-primary\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 244\n        },\n        __self: this\n      }, \"Try Now\")))))), __jsx(\"hr\", {\n        className: \"w-100\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 250\n        },\n        __self: this\n      }), __jsx(\"div\", {\n        className: \"row\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 251\n        },\n        __self: this\n      }, __jsx(\"div\", {\n        className: \"col-6\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 252\n        },\n        __self: this\n      }, __jsx(\"div\", {\n        className: \"card\",\n        style: {\n          styleCard: styleCard\n        },\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 253\n        },\n        __self: this\n      }, __jsx(\"div\", {\n        className: \"card-header\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 254\n        },\n        __self: this\n      }, \"Radom Forest Algorithm\"), __jsx(\"div\", {\n        className: \"card-body\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 255\n        },\n        __self: this\n      }, __jsx(\"h5\", {\n        className: \"card-title\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 261\n        },\n        __self: this\n      }, \"Explanation: \"), __jsx(\"p\", {\n        className: \"card-text\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 262\n        },\n        __self: this\n      }, \"The random forest is a model made up of many decision trees. Rather than just simply averaging the prediction of trees (which we could call a \\u201Cforest\\u201D), this model uses two key concepts that gives it the name random: Random sampling of training data points when building trees Random subsets of features considered when splitting nodes\"), __jsx(Link, {\n        route: \"mlalgo\",\n        params: {\n          path: \"forest\"\n        },\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 266\n        },\n        __self: this\n      }, __jsx(\"a\", {\n        className: \"btn btn-primary\",\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 267\n        },\n        __self: this\n      }, \"Try Now\"))))))));\n    }\n  }]);\n\n  return MlOptions;\n}(Component);\n\nexport default MlOptions;","map":{"version":3,"sources":["/Users/harsha.valluri/Desktop/cs407/DatApex/front-end/pages/mlOptions.js"],"names":["React","Component","Layout","Link","Router","styleCard","marginBottom","MlOptions","path"],"mappings":";;;;;;;AAAA,OAAOA,KAAP,IAAgBC,SAAhB,QAAiC,OAAjC;AACA,OAAOC,MAAP,MAAmB,sBAAnB,C,CACA;;AACA,SAASC,IAAT,EAAeC,MAAf,QAA6B,WAA7B;AAEA,IAAMC,SAAS,GAAG;AAChBC,EAAAA,YAAY,EAAE;AADE,CAAlB;;IAIMC,S;;;;;;;;;;;;;6BACK;AACP,aACE,4BACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,uCADF,EAEE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAFF,EAGE;AAAK,QAAA,SAAS,EAAC,iBAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAK,QAAA,SAAS,EAAC,KAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAK,QAAA,SAAS,EAAC,OAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAK,QAAA,SAAS,EAAC,MAAf;AAAsB,QAAA,KAAK,EAAE;AAACF,UAAAA,SAAS,EAATA;AAAD,SAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAK,QAAA,SAAS,EAAC,aAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,iCADF,EAEE;AAAK,QAAA,SAAS,EAAC,WAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AACE,QAAA,SAAS,EAAC,UADZ;AAEE,QAAA,OAAO,EAAC,KAFV;AAGE,QAAA,GAAG,EAAC,mBAHN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QADF,EAME;AAAI,QAAA,SAAS,EAAC,YAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBANF,EAOE;AAAG,QAAA,SAAS,EAAC,WAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,ogBASiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QATjB,ibAPF,EAyBE,MAAC,IAAD;AAAM,QAAA,KAAK,EAAC,QAAZ;AAAqB,QAAA,MAAM,EAAE;AAAEG,UAAAA,IAAI,EAAE;AAAR,SAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAG,QAAA,SAAS,EAAC,iBAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBADF,CAzBF,CAFF,CADF,CADF,EAmCE;AAAK,QAAA,SAAS,EAAC,OAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAK,QAAA,SAAS,EAAC,MAAf;AAAsB,QAAA,KAAK,EAAE;AAACH,UAAAA,SAAS,EAATA;AAAD,SAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAK,QAAA,SAAS,EAAC,aAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yCADF,EAEE;AAAK,QAAA,SAAS,EAAC,WAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AACE,QAAA,SAAS,EAAC,UADZ;AAEE,QAAA,OAAO,EAAC,KAFV;AAGE,QAAA,GAAG,EAAC,mBAHN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QADF,EAME;AAAI,QAAA,SAAS,EAAC,YAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBANF,EAOE;AAAG,QAAA,SAAS,EAAC,WAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,ydASE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QATF,+IAPF,EAqBE,MAAC,IAAD;AAAM,QAAA,KAAK,EAAC,QAAZ;AAAqB,QAAA,MAAM,EAAE;AAAEG,UAAAA,IAAI,EAAE;AAAR,SAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAG,QAAA,SAAS,EAAC,iBAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBADF,CArBF,CAFF,CADF,CAnCF,CADF,EAmEE;AAAI,QAAA,SAAS,EAAC,OAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAnEF,EAoEE;AAAK,QAAA,SAAS,EAAC,KAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAK,QAAA,SAAS,EAAC,OAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAK,QAAA,SAAS,EAAC,MAAf;AAAsB,QAAA,KAAK,EAAE;AAACH,UAAAA,SAAS,EAATA;AAAD,SAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAK,QAAA,SAAS,EAAC,aAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4CADF,EAIE;AAAK,QAAA,SAAS,EAAC,WAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AACE,QAAA,SAAS,EAAC,UADZ;AAEE,QAAA,OAAO,EAAC,KAFV;AAGE,QAAA,GAAG,EAAC,mBAHN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QADF,EAME;AAAI,QAAA,SAAS,EAAC,YAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBANF,EAOE;AAAG,QAAA,SAAS,EAAC,WAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qiBAUuC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAVvC,wJAPF,EAsBE,MAAC,IAAD;AAAM,QAAA,KAAK,EAAC,QAAZ;AAAqB,QAAA,MAAM,EAAE;AAAEG,UAAAA,IAAI,EAAE;AAAR,SAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAG,QAAA,SAAS,EAAC,iBAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBADF,CAtBF,CAJF,CADF,CADF,EAkCE;AAAK,QAAA,SAAS,EAAC,OAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAK,QAAA,SAAS,EAAC,MAAf;AAAsB,QAAA,KAAK,EAAE;AAACH,UAAAA,SAAS,EAATA;AAAD,SAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAK,QAAA,SAAS,EAAC,aAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,6BADF,EAEE;AAAK,QAAA,SAAS,EAAC,WAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AACE,QAAA,SAAS,EAAC,UADZ;AAEE,QAAA,OAAO,EAAC,KAFV;AAGE,QAAA,GAAG,EAAC,mBAHN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QADF,EAME;AAAI,QAAA,SAAS,EAAC,YAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBANF,EAOE;AAAG,QAAA,SAAS,EAAC,WAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,meAWE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAXF,EAYE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAZF,oIAeE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAfF,qFAiBE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAjBF,0CAkBE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAlBF,8EAoBE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QApBF,EAqBE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QArBF,0EAPF,EAgCE,MAAC,IAAD;AAAM,QAAA,KAAK,EAAC,QAAZ;AAAqB,QAAA,MAAM,EAAE;AAAEG,UAAAA,IAAI,EAAE;AAAR,SAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAG,QAAA,SAAS,EAAC,iBAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBADF,CAhCF,CAFF,CADF,CAlCF,CApEF,EAgJE;AAAI,QAAA,SAAS,EAAC,OAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAhJF,EAiJE;AAAK,QAAA,SAAS,EAAC,KAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAK,QAAA,SAAS,EAAC,OAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAK,QAAA,SAAS,EAAC,MAAf;AAAsB,QAAA,KAAK,EAAE;AAACH,UAAAA,SAAS,EAATA;AAAD,SAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAK,QAAA,SAAS,EAAC,aAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wCADF,EAEE;AAAK,QAAA,SAAS,EAAC,WAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AACE,QAAA,SAAS,EAAC,UADZ;AAEE,QAAA,OAAO,EAAC,KAFV;AAGE,QAAA,GAAG,EAAC,oBAHN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QADF,EAME;AAAI,QAAA,SAAS,EAAC,YAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBANF,EAOE;AAAG,QAAA,SAAS,EAAC,WAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0QAME;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QANF,6ZAcE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAdF,EAeE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAfF,qQAqBE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QArBF,0HAwBE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAxBF,yDAPF,EAiCE,MAAC,IAAD;AAAM,QAAA,KAAK,EAAC,QAAZ;AAAqB,QAAA,MAAM,EAAE;AAAEG,UAAAA,IAAI,EAAE;AAAR,SAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAG,QAAA,SAAS,EAAC,iBAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBADF,CAjCF,CAFF,CADF,CADF,EA2CE;AAAK,QAAA,SAAS,EAAC,OAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAK,QAAA,SAAS,EAAC,MAAf;AAAsB,QAAA,KAAK,EAAE;AAACH,UAAAA,SAAS,EAATA;AAAD,SAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAK,QAAA,SAAS,EAAC,aAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mCADF,EAEE;AAAK,QAAA,SAAS,EAAC,WAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AACE,QAAA,SAAS,EAAC,UADZ;AAEE,QAAA,OAAO,EAAC,KAFV;AAGE,QAAA,GAAG,EAAC,oBAHN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QADF,EAME;AAAI,QAAA,SAAS,EAAC,YAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBANF,EAOE;AAAG,QAAA,SAAS,EAAC,WAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,+aASE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QATF,EAUE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAVF,uPAgBE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAhBF,wEAkBE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAlBF,8HAqBE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QArBF,4GAuBE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAvBF,EAwBE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAxBF,8IAPF,EAoCE,MAAC,IAAD;AAAM,QAAA,KAAK,EAAC,QAAZ;AAAqB,QAAA,MAAM,EAAE;AAAEG,UAAAA,IAAI,EAAE;AAAR,SAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAG,QAAA,SAAS,EAAC,iBAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBADF,CApCF,CAFF,CADF,CA3CF,CAjJF,EA0OE;AAAI,QAAA,SAAS,EAAC,OAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QA1OF,EA2OE;AAAK,QAAA,SAAS,EAAC,KAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAK,QAAA,SAAS,EAAC,OAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAK,QAAA,SAAS,EAAC,MAAf;AAAsB,QAAA,KAAK,EAAE;AAACH,UAAAA,SAAS,EAATA;AAAD,SAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAK,QAAA,SAAS,EAAC,aAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kCADF,EAEE;AAAK,QAAA,SAAS,EAAC,WAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SAME;AAAI,QAAA,SAAS,EAAC,YAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBANF,EAOE;AAAG,QAAA,SAAS,EAAC,WAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qWAPF,EAWE,MAAC,IAAD;AAAM,QAAA,KAAK,EAAC,QAAZ;AAAqB,QAAA,MAAM,EAAE;AAAEG,UAAAA,IAAI,EAAE;AAAR,SAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE;AAAG,QAAA,SAAS,EAAC,iBAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBADF,CAXF,CAFF,CADF,CADF,CA3OF,CAHF,CADF;AAwQD;;;;EA1QqBP,S;;AA6QxB,eAAeM,SAAf","sourcesContent":["import React, { Component } from \"react\";\nimport Layout from \"../components/layout\";\n// import Link from 'next/link';\nimport { Link, Router } from \"../routes\";\n\nconst styleCard = {\n  marginBottom: \"10px\"\n};\n\nclass MlOptions extends Component {\n  render() {\n    return (\n      <>\n        <h1>Machine Learning Algorithms</h1>\n        <hr></hr>\n        <div className=\"container-fluid\">\n          <div className=\"row\">\n            <div className=\"col-6\">\n              <div className=\"card\" style={{styleCard}}>\n                <div className=\"card-header\">Naive Bayes Algorithm</div>\n                <div className=\"card-body\">\n                  <img\n                    className=\"card-img\"\n                    variant=\"top\"\n                    src=\"../static/nba.png\"\n                  />\n                  <h5 className=\"card-title\">Explanation: </h5>\n                  <p className=\"card-text\">\n                    Naïve Bayes is a classification technique/algorithm based on\n                    Bayes’ Theorem with an assumption of independence among the\n                    predictors. Loosely translated, this means that a Naïve\n                    Bayes classifier assumes that the presence of a particular\n                    feature in a class is unrelated to the presence of any other\n                    feature. This model is particularly useful for large data\n                    sets – along with simplicity, Naïve Bayes is known to\n                    outperform even highly sophisticated classification methods\n                    in some cases. <br></br>The Naïve Bayes algorithm works by\n                    converting the dataset into a frequency table, creating a\n                    likelihood table by calculating probabilities & then using\n                    the Naïve Bayes equation to calculate the posterior\n                    probability for each class. The class with the highest\n                    posterior probability is considered the outcome of the\n                    prediction. This algorithm is typically used in text\n                    classification & with problems having multiple classes.\n                  </p>\n                  <Link route=\"mlalgo\" params={{ path: \"nba\" }}>\n                    <a className=\"btn btn-primary\">Try Now</a>\n                  </Link>\n                </div>\n              </div>\n            </div>\n            <div className=\"col-6\">\n              <div className=\"card\" style={{styleCard}}>\n                <div className=\"card-header\">Logistic Regression Algorithm</div>\n                <div className=\"card-body\">\n                  <img\n                    className=\"card-img\"\n                    variant=\"top\"\n                    src=\"../static/lra.png\"\n                  />\n                  <h5 className=\"card-title\">Explanation: </h5>\n                  <p className=\"card-text\">\n                    Logistic Regression is a classification machine-learning\n                    algorithm used to assign observations to a discrete set of\n                    classes (binary or multiple classes). Logistic regression\n                    transforms its output using the logistic sigmoid function to\n                    return a probability value. Logistic Regression is a\n                    predictive analysis algorithm as it is based on the concepts\n                    of probability. It uses a more complex cost function than\n                    linear regression (the logistic or sigmoid function).\n                    <br></br>\n                    In order to map predicted values to probabilities, we use\n                    the Sigmoid function which maps any real value into another\n                    value between 0 & 1.\n                  </p>\n                  <Link route=\"mlalgo\" params={{ path: \"lra\" }}>\n                    <a className=\"btn btn-primary\">Try Now</a>\n                  </Link>\n                </div>\n              </div>\n            </div>\n          </div>\n          <hr className=\"w-100\" />\n          <div className=\"row\">\n            <div className=\"col-6\">\n              <div className=\"card\" style={{styleCard}}>\n                <div className=\"card-header\">\n                  Support Vector Machine Algorithm\n                </div>\n                <div className=\"card-body\">\n                  <img\n                    className=\"card-img\"\n                    variant=\"top\"\n                    src=\"../static/svm.png\"\n                  />\n                  <h5 className=\"card-title\">Explanation: </h5>\n                  <p className=\"card-text\">\n                    SVM is a supervised machine learning algorithm which may be\n                    used for either classification or regression problems.\n                    However, in general, it is used predominantly for\n                    classification problems. In this algorithm, we plot each\n                    data item as a point in n-dimensional space (n being the\n                    number of features) with the value of each feature being the\n                    value of a particular coordinate. Subsequently,\n                    classification is performed by finding the hyperplane (the\n                    equivalent of a line in a 2-dimensional space) that\n                    differentiates the two classes well. <br></br>Above image\n                    shows, Support Vectors are simply the co-ordinates of\n                    individual observations. SVM is a frontier which best\n                    segregates the two classes.\n                  </p>\n                  <Link route=\"mlalgo\" params={{ path: \"svm\" }}>\n                    <a className=\"btn btn-primary\">Try Now</a>\n                  </Link>\n                </div>\n              </div>\n            </div>\n            <div className=\"col-6\">\n              <div className=\"card\" style={{styleCard}}>\n                <div className=\"card-header\">Bagging Algorithm</div>\n                <div className=\"card-body\">\n                  <img\n                    className=\"card-img\"\n                    variant=\"top\"\n                    src=\"../static/bag.png\"\n                  />\n                  <h5 className=\"card-title\">Explanation: </h5>\n                  <p className=\"card-text\">\n                    Bagging algorithm is a simple yet powerful ensemble method.\n                    An ensemble method is one that combines predictions from\n                    multiple machine learning algorithms together to make more\n                    accurate predictions than any individual method.\n                    {/* <br /> */}\n                    This method is especially helpful in reducing the variance\n                    for algorithms which tend to have really high variance.\n                    Bagging involves applying the Bootstrapping procedure to a\n                    high-variance machine learning algorithm (typically decision\n                    trees).\n                    <br />\n                    <br />\n                    Let’s assume we have a sample dataset of 1000 instances & we\n                    are using the CART algorithm. Bagging would work as follows:\n                    <br />- Create several (e.g. 100) random sub-samples of the\n                    dataset with replacement.\n                    <br />- Train a CART model on each sample.\n                    <br />- Given a new dataset, calculate the average\n                    prediction from each model.\n                    <br />\n                    <br />\n                    Bagging may be used for either classification or regression\n                    problems.\n                  </p>\n                  <Link route=\"mlalgo\" params={{ path: \"bag\" }}>\n                    <a className=\"btn btn-primary\">Try Now</a>\n                  </Link>\n                </div>\n              </div>\n            </div>\n          </div>\n          <hr className=\"w-100\" />\n          <div className=\"row\">\n            <div className=\"col-6\">\n              <div className=\"card\" style={{styleCard}}>\n                <div className=\"card-header\">K-means Clustering Algorithm</div>\n                <div className=\"card-body\">\n                  <img\n                    className=\"card-img\"\n                    variant=\"top\"\n                    src=\"../static/clus.png\"\n                  />\n                  <h5 className=\"card-title\">Explanation: </h5>\n                  <p className=\"card-text\">\n                    K-means Clustering is one of the simplest and most popular\n                    unsupervised machine learning algorithms. Typically,\n                    unsupervised machine learning algorithms make inferences\n                    from datasets using only input vectors without referring to\n                    known/labelled outcomes.\n                    <br />\n                    A cluster, simply put, refers to a collection of data points\n                    aggregated together because of certain similarities. The ‘k’\n                    from the name refers to the number of centroids needed in\n                    the dataset, and is defined by us. A centroid is the\n                    imaginary or real location representing the center of the\n                    cluster. The ‘means’ in the K-Means refers to the averaging\n                    of data (i.e. finding the centroid).\n                    <br />\n                    <br />\n                    The algorithm starts with a first group of randomly selected\n                    centroids that are used as beginning points for every\n                    cluster, and then performs iterative calculations to\n                    optimize the positions of the centroids. It stops creating\n                    or optimizing clusters when:\n                    <br />- The centroids have stabilized, i.e. there is no\n                    change in their values because the clustering has been\n                    successful;\n                    <br />- The defined number of iterations has been reached.\n                  </p>\n                  <Link route=\"mlalgo\" params={{ path: \"clus\" }}>\n                    <a className=\"btn btn-primary\">Try Now</a>\n                  </Link>\n                </div>\n              </div>\n            </div>\n            <div className=\"col-6\">\n              <div className=\"card\" style={{styleCard}}>\n                <div className=\"card-header\">Decision Tree Algorithm</div>\n                <div className=\"card-body\">\n                  <img\n                    className=\"card-img\"\n                    variant=\"top\"\n                    src=\"../static/tree.png\"\n                  />\n                  <h5 className=\"card-title\">Explanation: </h5>\n                  <p className=\"card-text\">\n                    Decision Tree algorithm belongs to the family of supervised\n                    machine learning algorithms. Unlike other supervised\n                    learning algorithms, this algorithm can be used for solving\n                    regression & classification problems too. The general model\n                    of Decision Trees algorithm is to create a training model\n                    which can be used to predict the class or value of target\n                    variables by learning decision rules inferred from the\n                    training data.\n                    <br />\n                    <br />\n                    As the name insinuates, this algorithm uses a tree\n                    representation to solve the problem, wherein each internal\n                    node corresponds to an attribute while each leaf node\n                    corresponds to a class label. A rough outline of the\n                    algorithm is as follows:\n                    <br />- Place the best attribute of the dataset at the root\n                    of the tree.\n                    <br />- Split the training set into subsets in such a way\n                    that each subset contains data with the same value for an\n                    attribute.\n                    <br />- Repeat the previous two steps on each subset until\n                    leaf nodes are found in all branches of the tree.\n                    <br />\n                    <br />\n                    With decision trees, one of the biggest challenges is to\n                    identify which attributes need to be considered as the root\n                    node and each level.\n                  </p>\n                  <Link route=\"mlalgo\" params={{ path: \"tree\" }}>\n                    <a className=\"btn btn-primary\">Try Now</a>\n                  </Link>\n                </div>\n              </div>\n            </div>\n          </div>\n          <hr className=\"w-100\" />\n          <div className=\"row\">\n            <div className=\"col-6\">\n              <div className=\"card\" style={{styleCard}}>\n                <div className=\"card-header\">Radom Forest Algorithm</div>\n                <div className=\"card-body\">\n                  {/* <img\n                    className=\"card-img\"\n                    variant=\"top\"\n                    src=\"../static/tree.png\"\n                  /> */}\n                  <h5 className=\"card-title\">Explanation: </h5>\n                  <p className=\"card-text\">\n                    The random forest is a model made up of many decision trees. Rather than just simply averaging the prediction of trees (which we could call a “forest”), this model uses two key concepts that gives it the name random:\n  Random sampling of training data points when building trees Random subsets of features considered when splitting nodes\n                  </p>\n                  <Link route=\"mlalgo\" params={{ path: \"forest\" }}>\n                    <a className=\"btn btn-primary\">Try Now</a>\n                  </Link>\n                </div>\n              </div>\n            </div>\n          </div>\n        </div>\n      </>\n    );\n  }\n}\n\nexport default MlOptions;\n"]},"metadata":{},"sourceType":"module"}