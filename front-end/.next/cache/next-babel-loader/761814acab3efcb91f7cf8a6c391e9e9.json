{"ast":null,"code":"var _jsxFileName = \"/Users/seohyun/dataPex/front-end/pages/mlOptions.js\";\nvar __jsx = React.createElement;\nimport React, { Component } from \"react\";\nimport Layout from \"../components/layout\"; // import Link from 'next/link';\n\nimport { Link, Router } from \"../routes\";\nconst styleCard = {\n  marginBottom: \"10px\"\n};\n\nclass MlOptions extends Component {\n  render() {\n    return __jsx(Layout, {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 13\n      },\n      __self: this\n    }, __jsx(\"h1\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 14\n      },\n      __self: this\n    }, \"MLOptions\"), __jsx(\"hr\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 15\n      },\n      __self: this\n    }), __jsx(\"div\", {\n      className: \"container-fluid\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 16\n      },\n      __self: this\n    }, __jsx(\"div\", {\n      className: \"row\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 17\n      },\n      __self: this\n    }, __jsx(\"div\", {\n      className: \"col-6\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 18\n      },\n      __self: this\n    }, __jsx(\"div\", {\n      className: \"card\",\n      style: styleCard,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 19\n      },\n      __self: this\n    }, __jsx(\"div\", {\n      className: \"card-header\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 20\n      },\n      __self: this\n    }, \"Naive Bayes algorithm\"), __jsx(\"div\", {\n      className: \"card-body\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 21\n      },\n      __self: this\n    }, __jsx(\"img\", {\n      className: \"card-img\",\n      variant: \"top\",\n      src: \"../static/nba.png\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 22\n      },\n      __self: this\n    }), __jsx(\"h5\", {\n      className: \"card-title\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 27\n      },\n      __self: this\n    }, \"Explanation: \"), __jsx(\"p\", {\n      className: \"card-text\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 28\n      },\n      __self: this\n    }, \"Na\\xEFve Bayes is a classification technique/algorithm based on Bayes\\u2019 Theorem with an assumption of independence among the predictors. Loosely translated, this means that a Na\\xEFve Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature. This model is particularly useful for large data sets \\u2013 along with simplicity, Na\\xEFve Bayes is known to outperform even highly sophisticated classification methods in some cases. \", __jsx(\"br\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 37\n      },\n      __self: this\n    }), \"The Na\\xEFve Bayes algorithm works by converting the dataset into a frequency table, creating a likelihood table by calculating probabilities & then using the Na\\xEFve Bayes equation to calculate the posterior probability for each class. The class with the highest posterior probability is considered the outcome of the prediction. This algorithm is typically used in text classification & with problems having multiple classes.\"), __jsx(Link, {\n      route: \"mlalgo\",\n      params: {\n        path: \"nba\"\n      },\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 47\n      },\n      __self: this\n    }, __jsx(\"a\", {\n      className: \"btn btn-primary\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 48\n      },\n      __self: this\n    }, \"Go somewhere\"))))), __jsx(\"div\", {\n      className: \"col-6\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 53\n      },\n      __self: this\n    }, __jsx(\"div\", {\n      className: \"card\",\n      style: styleCard,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 54\n      },\n      __self: this\n    }, __jsx(\"div\", {\n      className: \"card-header\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 55\n      },\n      __self: this\n    }, \"Logistic Regression algorithm\"), __jsx(\"div\", {\n      className: \"card-body\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 56\n      },\n      __self: this\n    }, __jsx(\"img\", {\n      className: \"card-img\",\n      variant: \"top\",\n      src: \"../static/lra.png\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 57\n      },\n      __self: this\n    }), __jsx(\"h5\", {\n      className: \"card-title\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 62\n      },\n      __self: this\n    }, \"Explanation: \"), __jsx(\"p\", {\n      className: \"card-text\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 63\n      },\n      __self: this\n    }, \"Logistic Regression is a classification machine-learning algorithm used to assign observations to a discrete set of classes (binary or multiple classes). Logistic regression transforms its output using the logistic sigmoid function to return a probability value. Logistic Regression is a predictive analysis algorithm as it is based on the concepts of probability. It uses a more complex cost function than linear regression (the logistic or sigmoid function).\", __jsx(\"br\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 72\n      },\n      __self: this\n    }), \"In order to map predicted values to probabilities, we use the Sigmoid function which maps any real value into another value between 0 & 1.\"), __jsx(Link, {\n      route: \"mlalgo\",\n      params: {\n        path: \"lra\"\n      },\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 77\n      },\n      __self: this\n    }, __jsx(\"a\", {\n      className: \"btn btn-primary\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 78\n      },\n      __self: this\n    }, \"Go somewhere\"))))), __jsx(\"div\", {\n      className: \"col-6\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 83\n      },\n      __self: this\n    }, __jsx(\"div\", {\n      className: \"card\",\n      style: styleCard,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 84\n      },\n      __self: this\n    }, __jsx(\"div\", {\n      className: \"card-header\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 85\n      },\n      __self: this\n    }, \"Support Vector Machine algorithm\"), __jsx(\"div\", {\n      className: \"card-body\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 88\n      },\n      __self: this\n    }, __jsx(\"img\", {\n      className: \"card-img\",\n      variant: \"top\",\n      src: \"../static/svm.png\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 89\n      },\n      __self: this\n    }), __jsx(\"h5\", {\n      className: \"card-title\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 94\n      },\n      __self: this\n    }, \"Explanation: \"), __jsx(\"p\", {\n      className: \"card-text\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 95\n      },\n      __self: this\n    }, \"SVM is a supervised machine learning algorithm which may be used for either classification or regression problems. However, in general, it is used predominantly for classification problems. In this algorithm, we plot each data item as a point in n-dimensional space (n being the number of features) with the value of each feature being the value of a particular coordinate. Subsequently, classification is performed by finding the hyperplane (the equivalent of a line in a 2-dimensional space) that differentiates the two classes well. \", __jsx(\"br\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 105\n      },\n      __self: this\n    }), \"Above image shows, Support Vectors are simply the co-ordinates of individual observations. SVM is a frontier which best segregates the two classes.\"), __jsx(Link, {\n      route: \"mlalgo\",\n      params: {\n        path: \"svm\"\n      },\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 110\n      },\n      __self: this\n    }, __jsx(\"a\", {\n      className: \"btn btn-primary\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 111\n      },\n      __self: this\n    }, \"Go somewhere\"))))), __jsx(\"div\", {\n      className: \"col-6\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 116\n      },\n      __self: this\n    }, __jsx(\"div\", {\n      className: \"card\",\n      style: styleCard,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 117\n      },\n      __self: this\n    }, __jsx(\"div\", {\n      className: \"card-header\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 118\n      },\n      __self: this\n    }, \"Bagging algorithm\"), __jsx(\"div\", {\n      className: \"card-body\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 119\n      },\n      __self: this\n    }, __jsx(\"img\", {\n      className: \"card-img\",\n      variant: \"top\",\n      src: \"../static/bag.png\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 120\n      },\n      __self: this\n    }), __jsx(\"h5\", {\n      className: \"card-title\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 125\n      },\n      __self: this\n    }, \"Explanation: \"), __jsx(\"p\", {\n      className: \"card-text\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 126\n      },\n      __self: this\n    }, \"Bagging algorithm is a simple yet powerful ensemble method. An ensemble method is one that combines predictions from multiple machine learning algorithms together to make more accurate predictions than any individual method.\", __jsx(\"br\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 131\n      },\n      __self: this\n    }), \"This method is especially helpful in reducing the variance for algorithms which tend to have really high variance. Bagging involves applying the Bootstrapping procedure to a high-variance machine learning algorithm (typically decision trees).\", __jsx(\"br\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 137\n      },\n      __self: this\n    }), __jsx(\"br\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 137\n      },\n      __self: this\n    }), \"Let\\u2019s assume we have a sample dataset of 1000 instances & we are using the CART algorithm. Bagging would work as follows:\", __jsx(\"br\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 140\n      },\n      __self: this\n    }), \"- Create several (e.g. 100) random sub-samples of the dataset with replacement.\", __jsx(\"br\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 142\n      },\n      __self: this\n    }), \"- Train a CART model on each sample.\", __jsx(\"br\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 143\n      },\n      __self: this\n    }), \"- Given a new dataset, calculate the average prediction from each model.\", __jsx(\"br\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 145\n      },\n      __self: this\n    }), __jsx(\"br\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 145\n      },\n      __self: this\n    }), \"Bagging may be used for either classification or regression problems.\"), __jsx(Link, {\n      route: \"mlalgo\",\n      params: {\n        path: \"bag\"\n      },\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 149\n      },\n      __self: this\n    }, __jsx(\"a\", {\n      className: \"btn btn-primary\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 150\n      },\n      __self: this\n    }, \"Go somewhere\"))))), __jsx(\"div\", {\n      className: \"col-6\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 155\n      },\n      __self: this\n    }, __jsx(\"div\", {\n      className: \"card\",\n      style: styleCard,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 156\n      },\n      __self: this\n    }, __jsx(\"div\", {\n      className: \"card-header\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 157\n      },\n      __self: this\n    }, \"Clustering algorithm\"), __jsx(\"div\", {\n      className: \"card-body\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 158\n      },\n      __self: this\n    }, __jsx(\"img\", {\n      className: \"card-img\",\n      variant: \"top\",\n      src: \"../static/clus.png\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 159\n      },\n      __self: this\n    }), __jsx(\"h5\", {\n      className: \"card-title\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 164\n      },\n      __self: this\n    }, \"Explanation: \"), __jsx(\"p\", {\n      className: \"card-text\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 165\n      },\n      __self: this\n    }, \"K-means Clustering is one of the simplest and most popular unsupervised machine learning algorithms. Typically, unsupervised machine learning algorithms make inferences from datasets using only input vectors without referring to known/labelled outcomes.\", __jsx(\"br\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 167\n      },\n      __self: this\n    }), \"A cluster, simply put, refers to a collection of data points aggregated together because of certain similarities. The \\u2018k\\u2019 from the name refers to the number of centroids needed in the dataset, and is defined by us. A centroid is the imaginary or real location representing the center of the cluster. The \\u2018means\\u2019 in the K-Means refers to the averaging of data (i.e. finding the centroid).\", __jsx(\"br\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 169\n      },\n      __self: this\n    }), __jsx(\"br\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 169\n      },\n      __self: this\n    }), \"The algorithm starts with a first group of randomly selected centroids that are used as beginning points for every cluster, and then performs iterative calculations to optimize the positions of the centroids. It stops creating or optimizing clusters when:\", __jsx(\"br\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 173\n      },\n      __self: this\n    }), \"- The centroids have stabilized, i.e. there is no change in their values because the clustering has been successful;\", __jsx(\"br\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 174\n      },\n      __self: this\n    }), \"- The defined number of iterations has been reached.\"), __jsx(Link, {\n      route: \"mlalgo\",\n      params: {\n        path: \"clus\"\n      },\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 177\n      },\n      __self: this\n    }, __jsx(\"a\", {\n      className: \"btn btn-primary\",\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 178\n      },\n      __self: this\n    }, \"Go somewhere\"))))))));\n  }\n\n}\n\nexport default MlOptions;","map":{"version":3,"sources":["/Users/seohyun/dataPex/front-end/pages/mlOptions.js"],"names":["React","Component","Layout","Link","Router","styleCard","marginBottom","MlOptions","render","path"],"mappings":";;AAAA,OAAOA,KAAP,IAAgBC,SAAhB,QAAiC,OAAjC;AACA,OAAOC,MAAP,MAAmB,sBAAnB,C,CACA;;AACA,SAASC,IAAT,EAAeC,MAAf,QAA6B,WAA7B;AAEA,MAAMC,SAAS,GAAG;AAChBC,EAAAA,YAAY,EAAE;AADE,CAAlB;;AAIA,MAAMC,SAAN,SAAwBN,SAAxB,CAAkC;AAChCO,EAAAA,MAAM,GAAG;AACP,WACE,MAAC,MAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBADF,EAEE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAFF,EAGE;AAAK,MAAA,SAAS,EAAC,iBAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AAAK,MAAA,SAAS,EAAC,KAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AAAK,MAAA,SAAS,EAAC,OAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AAAK,MAAA,SAAS,EAAC,MAAf;AAAsB,MAAA,KAAK,EAAEH,SAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AAAK,MAAA,SAAS,EAAC,aAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,+BADF,EAEE;AAAK,MAAA,SAAS,EAAC,WAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AACE,MAAA,SAAS,EAAC,UADZ;AAEE,MAAA,OAAO,EAAC,KAFV;AAGE,MAAA,GAAG,EAAC,mBAHN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MADF,EAME;AAAI,MAAA,SAAS,EAAC,YAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,uBANF,EAOE;AAAG,MAAA,SAAS,EAAC,WAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kgBASiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MATjB,ibAPF,EA0BE,MAAC,IAAD;AAAM,MAAA,KAAK,EAAC,QAAZ;AAAqB,MAAA,MAAM,EAAE;AAAEI,QAAAA,IAAI,EAAE;AAAR,OAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AAAG,MAAA,SAAS,EAAC,iBAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,sBADF,CA1BF,CAFF,CADF,CADF,EAoCE;AAAK,MAAA,SAAS,EAAC,OAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AAAK,MAAA,SAAS,EAAC,MAAf;AAAsB,MAAA,KAAK,EAAEJ,SAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AAAK,MAAA,SAAS,EAAC,aAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,uCADF,EAEE;AAAK,MAAA,SAAS,EAAC,WAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AACE,MAAA,SAAS,EAAC,UADZ;AAEE,MAAA,OAAO,EAAC,KAFV;AAGE,MAAA,GAAG,EAAC,mBAHN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MADF,EAME;AAAI,MAAA,SAAS,EAAC,YAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,uBANF,EAOE;AAAG,MAAA,SAAS,EAAC,WAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,udASE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MATF,+IAPF,EAqBE,MAAC,IAAD;AAAM,MAAA,KAAK,EAAC,QAAZ;AAAqB,MAAA,MAAM,EAAE;AAAEI,QAAAA,IAAI,EAAE;AAAR,OAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AAAG,MAAA,SAAS,EAAC,iBAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,sBADF,CArBF,CAFF,CADF,CApCF,EAkEE;AAAK,MAAA,SAAS,EAAC,OAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AAAK,MAAA,SAAS,EAAC,MAAf;AAAsB,MAAA,KAAK,EAAEJ,SAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AAAK,MAAA,SAAS,EAAC,aAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0CADF,EAIE;AAAK,MAAA,SAAS,EAAC,WAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AACE,MAAA,SAAS,EAAC,UADZ;AAEE,MAAA,OAAO,EAAC,KAFV;AAGE,MAAA,GAAG,EAAC,mBAHN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MADF,EAME;AAAI,MAAA,SAAS,EAAC,YAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,uBANF,EAOE;AAAG,MAAA,SAAS,EAAC,WAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,miBAUuC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAVvC,wJAPF,EAsBE,MAAC,IAAD;AAAM,MAAA,KAAK,EAAC,QAAZ;AAAqB,MAAA,MAAM,EAAE;AAAEI,QAAAA,IAAI,EAAE;AAAR,OAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AAAG,MAAA,SAAS,EAAC,iBAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,sBADF,CAtBF,CAJF,CADF,CAlEF,EAmGE;AAAK,MAAA,SAAS,EAAC,OAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AAAK,MAAA,SAAS,EAAC,MAAf;AAAsB,MAAA,KAAK,EAAEJ,SAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AAAK,MAAA,SAAS,EAAC,aAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BADF,EAEE;AAAK,MAAA,SAAS,EAAC,WAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AACE,MAAA,SAAS,EAAC,UADZ;AAEE,MAAA,OAAO,EAAC,KAFV;AAGE,MAAA,GAAG,EAAC,mBAHN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MADF,EAME;AAAI,MAAA,SAAS,EAAC,YAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,uBANF,EAOE;AAAG,MAAA,SAAS,EAAC,WAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2OAKE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MALF,wPAWE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAXF,EAWQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAXR,oIAcE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAdF,qFAgBE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAhBF,0CAiBE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAjBF,8EAmBE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAnBF,EAmBQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAnBR,0EAPF,EA8BE,MAAC,IAAD;AAAM,MAAA,KAAK,EAAC,QAAZ;AAAqB,MAAA,MAAM,EAAE;AAAEI,QAAAA,IAAI,EAAE;AAAR,OAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AAAG,MAAA,SAAS,EAAC,iBAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,sBADF,CA9BF,CAFF,CADF,CAnGF,EA0IE;AAAK,MAAA,SAAS,EAAC,OAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AAAK,MAAA,SAAS,EAAC,MAAf;AAAsB,MAAA,KAAK,EAAEJ,SAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AAAK,MAAA,SAAS,EAAC,aAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,8BADF,EAEE;AAAK,MAAA,SAAS,EAAC,WAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AACE,MAAA,SAAS,EAAC,UADZ;AAEE,MAAA,OAAO,EAAC,KAFV;AAGE,MAAA,GAAG,EAAC,oBAHN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MADF,EAME;AAAI,MAAA,SAAS,EAAC,YAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,uBANF,EAOE;AAAG,MAAA,SAAS,EAAC,WAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wQAElB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAFkB,6ZAIlB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAJkB,EAIZ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAJY,qQAQlB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MARkB,0HASlB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MATkB,yDAPF,EAmBE,MAAC,IAAD;AAAM,MAAA,KAAK,EAAC,QAAZ;AAAqB,MAAA,MAAM,EAAE;AAAEI,QAAAA,IAAI,EAAE;AAAR,OAA7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AAAG,MAAA,SAAS,EAAC,iBAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,sBADF,CAnBF,CAFF,CADF,CA1IF,CADF,CAHF,CADF;AA+KD;;AAjL+B;;AAoLlC,eAAeF,SAAf","sourcesContent":["import React, { Component } from \"react\";\nimport Layout from \"../components/layout\";\n// import Link from 'next/link';\nimport { Link, Router } from \"../routes\";\n\nconst styleCard = {\n  marginBottom: \"10px\"\n};\n\nclass MlOptions extends Component {\n  render() {\n    return (\n      <Layout>\n        <h1>MLOptions</h1>\n        <hr></hr>\n        <div className=\"container-fluid\">\n          <div className=\"row\">\n            <div className=\"col-6\">\n              <div className=\"card\" style={styleCard}>\n                <div className=\"card-header\">Naive Bayes algorithm</div>\n                <div className=\"card-body\">\n                  <img\n                    className=\"card-img\"\n                    variant=\"top\"\n                    src=\"../static/nba.png\"\n                  />\n                  <h5 className=\"card-title\">Explanation: </h5>\n                  <p className=\"card-text\">\n                    Naïve Bayes is a classification technique/algorithm based on\n                    Bayes’ Theorem with an assumption of independence among the\n                    predictors. Loosely translated, this means that a Naïve\n                    Bayes classifier assumes that the presence of a particular\n                    feature in a class is unrelated to the presence of any other\n                    feature. This model is particularly useful for large data\n                    sets – along with simplicity, Naïve Bayes is known to\n                    outperform even highly sophisticated classification methods\n                    in some cases. <br></br>The Naïve Bayes algorithm works by\n                    converting the dataset into a frequency table, creating a\n                    likelihood table by calculating probabilities & then using\n                    the Naïve Bayes equation to calculate the posterior\n                    probability for each class. The class with the highest\n                    posterior probability is considered the outcome of the\n                    prediction. This algorithm is typically used in text\n                    classification & with problems having multiple classes.\n                  </p>\n\n                  <Link route=\"mlalgo\" params={{ path: \"nba\" }}>\n                    <a className=\"btn btn-primary\">Go somewhere</a>\n                  </Link>\n                </div>\n              </div>\n            </div>\n            <div className=\"col-6\">\n              <div className=\"card\" style={styleCard}>\n                <div className=\"card-header\">Logistic Regression algorithm</div>\n                <div className=\"card-body\">\n                  <img\n                    className=\"card-img\"\n                    variant=\"top\"\n                    src=\"../static/lra.png\"\n                  />\n                  <h5 className=\"card-title\">Explanation: </h5>\n                  <p className=\"card-text\">\n                    Logistic Regression is a classification machine-learning\n                    algorithm used to assign observations to a discrete set of\n                    classes (binary or multiple classes). Logistic regression\n                    transforms its output using the logistic sigmoid function to\n                    return a probability value. Logistic Regression is a\n                    predictive analysis algorithm as it is based on the concepts\n                    of probability. It uses a more complex cost function than\n                    linear regression (the logistic or sigmoid function).\n                    <br></br>\n                    In order to map predicted values to probabilities, we use\n                    the Sigmoid function which maps any real value into another\n                    value between 0 & 1.\n                  </p>\n                  <Link route=\"mlalgo\" params={{ path: \"lra\" }}>\n                    <a className=\"btn btn-primary\">Go somewhere</a>\n                  </Link>\n                </div>\n              </div>\n            </div>\n            <div className=\"col-6\">\n              <div className=\"card\" style={styleCard}>\n                <div className=\"card-header\">\n                  Support Vector Machine algorithm\n                </div>\n                <div className=\"card-body\">\n                  <img\n                    className=\"card-img\"\n                    variant=\"top\"\n                    src=\"../static/svm.png\"\n                  />\n                  <h5 className=\"card-title\">Explanation: </h5>\n                  <p className=\"card-text\">\n                    SVM is a supervised machine learning algorithm which may be\n                    used for either classification or regression problems.\n                    However, in general, it is used predominantly for\n                    classification problems. In this algorithm, we plot each\n                    data item as a point in n-dimensional space (n being the\n                    number of features) with the value of each feature being the\n                    value of a particular coordinate. Subsequently,\n                    classification is performed by finding the hyperplane (the\n                    equivalent of a line in a 2-dimensional space) that\n                    differentiates the two classes well. <br></br>Above image\n                    shows, Support Vectors are simply the co-ordinates of\n                    individual observations. SVM is a frontier which best\n                    segregates the two classes.\n                  </p>\n                  <Link route=\"mlalgo\" params={{ path: \"svm\" }}>\n                    <a className=\"btn btn-primary\">Go somewhere</a>\n                  </Link>\n                </div>\n              </div>\n            </div>\n            <div className=\"col-6\">\n              <div className=\"card\" style={styleCard}>\n                <div className=\"card-header\">Bagging algorithm</div>\n                <div className=\"card-body\">\n                  <img\n                    className=\"card-img\"\n                    variant=\"top\"\n                    src=\"../static/bag.png\"\n                  />\n                  <h5 className=\"card-title\">Explanation: </h5>\n                  <p className=\"card-text\">\n                    Bagging algorithm is a simple yet powerful ensemble method.\n                    An ensemble method is one that combines predictions from\n                    multiple machine learning algorithms together to make more\n                    accurate predictions than any individual method.\n                    <br />\n                    This method is especially helpful in reducing the variance\n                    for algorithms which tend to have really high variance.\n                    Bagging involves applying the Bootstrapping procedure to a\n                    high-variance machine learning algorithm (typically decision\n                    trees).\n                    <br /><br />\n                    Let’s assume we have a sample dataset of 1000 instances & we\n                    are using the CART algorithm. Bagging would work as follows:\n                    <br />- Create several (e.g. 100) random sub-samples of the\n                    dataset with replacement.\n                    <br />- Train a CART model on each sample.\n                    <br />- Given a new dataset, calculate the average\n                    prediction from each model.\n                    <br /><br />\n                    Bagging may be used for either classification or regression\n                    problems.\n                  </p>\n                  <Link route=\"mlalgo\" params={{ path: \"bag\" }}>\n                    <a className=\"btn btn-primary\">Go somewhere</a>\n                  </Link>\n                </div>\n              </div>\n            </div>\n            <div className=\"col-6\">\n              <div className=\"card\" style={styleCard}>\n                <div className=\"card-header\">Clustering algorithm</div>\n                <div className=\"card-body\">\n                  <img\n                    className=\"card-img\"\n                    variant=\"top\"\n                    src=\"../static/clus.png\"\n                  />\n                  <h5 className=\"card-title\">Explanation: </h5>\n                  <p className=\"card-text\">\n                  K-means Clustering is one of the simplest and most popular unsupervised machine learning algorithms. Typically, unsupervised machine learning algorithms make inferences from datasets using only input vectors without referring to known/labelled outcomes.\n<br />\nA cluster, simply put, refers to a collection of data points aggregated together because of certain similarities. The ‘k’ from the name refers to the number of centroids needed in the dataset, and is defined by us. A centroid is the imaginary or real location representing the center of the cluster. The ‘means’ in the K-Means refers to the averaging of data (i.e. finding the centroid).\n<br /><br />\n \n\nThe algorithm starts with a first group of randomly selected centroids that are used as beginning points for every cluster, and then performs iterative calculations to optimize the positions of the centroids. It stops creating or optimizing clusters when:\n<br />-\tThe centroids have stabilized, i.e. there is no change in their values because the clustering has been successful;\n<br />-\tThe defined number of iterations has been reached.\n\n                  </p>\n                  <Link route=\"mlalgo\" params={{ path: \"clus\" }}>\n                    <a className=\"btn btn-primary\">Go somewhere</a>\n                  </Link>\n                </div>\n              </div>\n            </div>\n          </div>\n        </div>\n      </Layout>\n    );\n  }\n}\n\nexport default MlOptions;\n"]},"metadata":{},"sourceType":"module"}